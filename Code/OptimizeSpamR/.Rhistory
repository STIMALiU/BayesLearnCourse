pointColor = plotColors[5] # Color for single dots
T = 200     # Length of time series
tStar = 60 # Intervention time
phi = 0.9  # AR(1) coefficient
psi = 0.5    # Size of intervention
sigmaEps = 0.05 # Standard deviation of epsilon
d = rep(0,T)
d[tStar:T] = 1
par(mfrow=c(1,2))
# Regular AR(1)
xMean = rep(0,T)
for (t in 2:T){
xMean[t] <- phi*xMean[t-1] + psi*d[t]
}
x = rep(0,T)
for (t in 2:T){
x[t] <- phi*x[t-1] + psi*d[t] + rnorm(1,mean = 0, sd = sigmaEps)
}
plot(1:T,xMean, type ="l", col = plotColors[2], ylim = c(-0.5,7), ylab = 'x(t)', xlab = "t", lwd = 3, main = "AR")
lines(1:T,x, col = plotColors[6], lwd = 1)
lines(1:T,d, col = plotColors[3], lwd = 1)
legend(x = "topleft", inset=.05, legend = c("Mean", "Time series","Dummy" ), lty = c(1,1,1), lwd = c(3,1,1), col = c(plotColors[2], plotColors[6], plotColors[3]), cex = 0.7)
# Steady-state AR(1)
xMean = rep(0,T)
for (t in 2:T){
xMean[t] <- psi*d[t] +  phi*(xMean[t-1] - psi*d[t-1])
}
x = rep(0,T)
for (t in 2:T){
x[t] <- psi*d[t] +  phi*(xMean[t-1] - psi*d[t-1]) + rnorm(1,mean = 0, sd = sigmaEps)
}
plot(1:T,xMean, type ="l", col = plotColors[2], ylim = c(-0.5,1), ylab = 'x(t)', xlab = "t", lwd = 3, main = "Steady-state AR")
lines(1:T,x, col = plotColors[6], lwd = 1)
lines(1:T,d, col = plotColors[3], lwd = 1)
legend(x = "topleft", inset=.05, legend = c("Mean", "Time series","Dummy" ), lty = c(1,1,1), lwd = c(3,1,1), col = c(plotColors[2], plotColors[6], plotColors[3]), cex = 0.7)
a = 1
a = 1
b = 10
a = b*3
a = 1
b = 10
data <- read.csv(file ='/home/mv/Downloads/smhi-opendata_1_86340_20200110_144752.csv', header=TRUE)
head(data)
data[1:10,]
data <- read.csv(file ='/home/mv/Downloads/sthlm.csv')
data <- read.csv(file ='/home/mv/Downloads/bromma.csv')
data[1:10,]
data <- read.csv(file ='/home/mv/Downloads/bromma.csv', sep=';', header = FALSE)
data[1:10,]
tail(data)
2019-1955
65*24
65*24*365
data <- read.csv(file ='/home/mv/Downloads/smhi-opendata_1_86340_20200110_144752.csv', header=TRUE)
head(data)
data <- read.csv(file ='/home/mv/Downloads/bromma.csv', sep=';', header = FALSE)
dim(data)
head(data)
tail(data,30)
plot(data[:,4])
plot(data[,4])
data <- read.csv(file ='/home/mv/Downloads/bromma.csv', sep=';', header = FALSE, stringsAsFactors = FALSE)
plot(data[,4])
head(data)
plot(data[,3])
plot(data[1:10,3])
plot(data[1:10,3], type = "l")
plot(data[1:1000,3], type = "l")
plot(data[1:10000,3], type = "l")
plot(data[1:30000,3], type = "l")
data[1,2]
data[1,2][1:2]
as.numeric(data[1,2])
substr(data[1,2],1,2)
a = substr(data[1,2],1,2)
a
as.numeric(a)
substr(data[1:3,2],1,2)
substr(data[1:3,2],1,2)[1]
substr(data[1:3,2],1,2)[1]
substr(data[1:3,2],1,2)[2]
as.numeric(substr(data[1:3,2],1,2))
as.numeric(substr(data[1:3,2],1,2))
b = as.numeric(substr(data[1:3,2],1,2))
type(b)
class(b)
b[1]
hour = as.numeric(substr(data[,2],1,2))
length(hour)
a = diff(hour)
a[1:100]
plot(a, type = "l")
b = frequency(a)
b
table(a)
c,d = hist(a)
d = hist(a)
d$counts
d$breaks
count(a)
install.packages('plyr')
library(plyr)
count(a)
colSums(count(a))
colSums(count(a[10000:]))
colSums(count(a[10000:507845]))
colSums(count(a[10000:507844]))
colSums(count(a))
count(a)
colSums(count(a))
count(a)
count(a[10000:length(a)])
count(a[100000:length(a)])
count(a[400000:length(a)])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
dim(data)
source('~/.active-rstudio-document')
dim(data)
source('~/.active-rstudio-document')
dim(data)
x
y
source('~/.active-rstudio-document')
RFsimulate(model, x=x, y=y)
data
dim(data)
RFsimulate(model, x=x, y=y)
#set.seed(71) # Set the seed for reproducibility
n = c(100,100)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
len(x1)
length(x1)
length(x2)
# Simulate from the Gaussian random field over the parcels and compute prior inclusion probabilities
sigma = 10          # Prior variance
ell = 20            # Kernel length scale
nu = 30/2            # Smoothness
nugget = 1          # Nugget
#model = RMexp(var=sigma^2, scale=ell) + RMnugget(var=nugget)                     # Exponential kernel with nugget
model = RMmatern(nu = nu, var=sigma^2, scale=ell) + RMnugget(var=nugget)          # Matern(nu) kernel with nugget
#model = RMgauss(var=sigma^2, scale=ell) + RMnugget(var=nugget)                    # Gaussian kernel with nugget (Not quite squared exp?)
S = RandomFields::RFsimulate(model, x1, x2)  # Simulate a GRF over the parcel raster
Y = as.matrix(S) # Returns the realization as a regular matrix
dim(Y)
library(RandomFields)
RFoptions(seed=0) ## *ANY* simulation will have the random seed 0; set
## RFoptions(seed=NA) to make them all random again
require("mvtnorm")
pts <- 100
repet <- 1
model <- RMexp()
x <- runif(n=pts, min=-1, max=1)
y <- runif(n=pts, min=-1, max=1)
data <- as.matrix(RFsimulate(model, x=x, y=y))
x
y
dim(data)
data
pts <- 100
model <- RMexp()
x <- runif(n=pts, min=-1, max=1)
y <- runif(n=pts, min=-1, max=1)
data <- as.matrix(RFsimulate(model, x=x, y=y))
dim(data)
data
length(data)
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
x <- runif(n=pts, min=-1, max=1)
y <- runif(n=pts, min=-1, max=1)
data <- as.matrix(RFsimulate(model, x=x, y=y))
data
n = c(100,100)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1, y=x2))
data
print(cbind(x, y, data))
n = c(10,10)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1, y=x2))
likeli <- RFlikelihood(model, x=x1, y=x2, data=data)
likeli$loglikelihood
n = c(100,100)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1, y=x2))
likeli <- RFlikelihood(model, x=x1, y=x2, data=data)
likeli$loglikelihood
?RFfit
## RFoptions(seed=NA) to make them all random again
n = c(30,20)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1, y=x2))
likeli <- RFlikelihood(model, x=x1, y=x2, data=data)
likeli$loglikelihood
fit = RFfit(model, x, y, data = data)
model = RMmatern(nu = 5/2, var=5^2, scale=NA) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
fit = RFfit(model, x, y, data = data)
fit
print(fit)
model = RMmatern(nu = 5/2, var=NA, scale=NA) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
fit = RFfit(model, x, y, data = data)
print(fit)
model = RMmatern(nu = 5/2, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x, y, data = data)
print(fit)
## RFoptions(seed=NA) to make them all random again
n = c(50,20)
Deltas = c(1,0.5)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
x2 = seq(0,(n[2]-1)*Deltas[2], by = Deltas[2])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1, y=x2))
likeli <- RFlikelihood(model, x=x1, y=x2, data=data)
likeli$loglikelihood
model = RMmatern(nu = 5/2, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x, y, data = data)
print(fit)
model = RMmatern(nu = 5/2, var=NA, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
fit = RFfit(model, x, y, data = data)
model = RMmatern(nu = 5/2, var=NA, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
model = RMmatern(nu = 5/2, var=NA, scale=NA) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
model = RMmatern(nu = 5/2, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
RFoptions(modus_operandi="sloppy") # "careless", "sloppy", "easygoing", "normal", "precise", "pedantic", "neurotic"
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
RFoptions(modus_operandi="careless") # "careless", "sloppy", "easygoing", "normal", "precise", "pedantic", "neurotic"
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
RFoptions(modus_operandi="normal") # "careless", "sloppy", "easygoing", "normal", "precise", "pedantic", "neurotic"
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data)
print(fit)
attributes(fit)
fit = RFfit(model, x = x1, y = x2, data = data, spConform=FALSE)
fit
fit$ml
fit$ml[1,]
dim(fit$ml)
fit$ml[1]
fit$ml$param
fit$ml$param[1,]
fit$ml$param[1,1]
fit$ml$param[1,2]
fit$ml$param[1,]
fit = RFfit(model, x = x1, y = x2, data = data, spConform='FALSE')
fit = RFfit(model, x = x1, y = x2, data = data, spConform=0)
fit$ml
fit$ml['param']
n = c(50)
Deltas = c(1)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1))
data
plot(data)
plot(data,type = "l")
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, y = x2, data = data, spConform=0)
fit = RFfit(model, x = x1, data = data, spConform=0)
print(fit)
n = c(100)
Deltas = c(1)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1))
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, data = data, spConform=0)
print(fit)
n = c(500)
Deltas = c(1)
x1 = seq(0,(n[1]-1)*Deltas[1], by = Deltas[1])
model = RMmatern(nu = 5/2, var=5^2, scale=2) + RMnugget(var=0.1)          # Matern(nu) kernel with nugget
data <- as.matrix(RFsimulate(model, x=x1))
model = RMmatern(nu = NA, var=NA, scale=NA) + RMnugget(var=NA)          # Matern(nu) kernel with nugget
fit = RFfit(model, x = x1, data = data, spConform=0)
print(fit)
sqrt(2)
K = 100000
psi = 0.5
psi = 0.13
K*psi
sqrt(K*psi*(1-psi))
K - 1.96*sqrt(K*psi*(1-psi))
K + 1.96*sqrt(K*psi*(1-psi))
K = 100
K + 1.96*sqrt(K*psi*(1-psi))
K + 1.96*sqrt(K*psi*(1-psi))
psi
K*psi
K*psi + 1.96*sqrt(K*psi*(1-psi))
K = 1000
K*psi + 1.96*sqrt(K*psi*(1-psi))
c(K*psi - 1.96*sqrt(K*psi*(1-psi)),K*psi + 1.96*sqrt(K*psi*(1-psi)))
K = 10000;c(K*psi - 1.96*sqrt(K*psi*(1-psi)),K*psi + 1.96*sqrt(K*psi*(1-psi)))
K = 100000;c(K*psi - 1.96*sqrt(K*psi*(1-psi)),K*psi + 1.96*sqrt(K*psi*(1-psi)))
1100000/21030
install.packages("devtools")
install.packages("roxygen")
install.packages("Roxygen")
library('devtools')
install.packages("Roxygen2")
install.packages("roxygen2")
library(devtools)
library(roxygen2)
install.packages("juliacall")
install.packages("JuliaCall")
library(JuliaCall)
julia_command("a = sqrt(2);")
julia_setup(JULIA_HOME = "~/Julia/julia-1.3.1/bin/")
julia_setup(JULIA_HOME = "~/Julia/julia-1.3.1/bin/julia")
julia_setup(JULIA_HOME = "~/Julia/julia-1.3.1/")
julia_setup(JULIA_HOME = "~/Julia/julia-1.3.1/bin")
julia_setup(JULIA_HOME = "~/Julia/julia-1.3.1/bin/")
JuliaCall:::julia_locate(JULIA_HOME = NULL)
julia_setup()
JuliaCall::julia_locate(JULIA_HOME = NULL)
library(JuliaCall)
julia_setup()
JuliaCall::julia_setup(rebuild = TRUE)
library(ggplot2)
install.packages('boot')
R.home()
library(RandomFields)
library(MASS)
Data = rnorm(n = 100, mean = 2, sd = 3)
xBar <- mean(Data)
s2 <- var(Data)
n <- length(Data)
NormalNonInfoPrior<-function(NDraws,Data){
PostDraws = matrix(0,NDraws,2)
PostDraws[,2]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,1]<-Datamean+rnorm(NDraws,0,1)*sqrt(PostDraws[,2]/n)
return(PostDraws)
}
NDraws = 1000
PostDraws<-NormalNonInfoPrior(1000,Data)
Data = rnorm(n = 100, mean = 2, sd = 3)
xBar <- mean(Data)
s2 <- var(Data)
n <- length(Data)
NormalNonInfoPrior<-function(NDraws, xBar, s2){
PostDraws = matrix(0,NDraws,2)
PostDraws[,2]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,1]<- xBar +rnorm(NDraws,0,1)*sqrt(PostDraws[,2]/n)
return(PostDraws)
}
NDraws = 1000
PostDraws<-NormalNonInfoPrior(1000,Data)
Data = rnorm(n = 100, mean = 2, sd = 3)
xBar <- mean(Data)
s2 <- var(Data)
n <- length(Data)
NormalNonInfoPrior<-function(NDraws, xBar, s2){
PostDraws = matrix(0,NDraws,2)
PostDraws[,2]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,1]<- xBar +rnorm(NDraws,0,1)*sqrt(PostDraws[,2]/n)
return(PostDraws)
}
NDraws = 1000
PostDraws<-NormalNonInfoPrior(1000, xBar, s2)
hist(PostDraws[,1]) 			# Plotting the histogram of mu-draws
Data = rnorm(n = 100, mean = 2, sd = 3)
xBar <- mean(Data)
s2 <- var(Data)
n <- length(Data)
NormalNonInfoPrior<-function(NDraws, xBar, s2){
PostDraws = matrix(0,NDraws,2)
PostDraws[,2]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,1]<- xBar +rnorm(NDraws,0,1)*sqrt(PostDraws[,2]/n)
return(PostDraws)
}
NDraws = 1000
PostDraws<-NormalNonInfoPrior(1000, xBar, s2)
hist(PostDraws[,1])
hist(PostDraws[,1], 50)
NDraws = 10000
PostDraws<-NormalNonInfoPrior(1000, xBar, s2)
hist(PostDraws[,1], 50)
hist(PostDraws[,2], 50)
Data = rnorm(n = 100, mean = 2, sd = 3)
xBar <- mean(Data)
s2 <- var(Data)
n <- length(Data)
NormalNonInfoPrior<-function(NDraws, xBar, s2){
PostDraws = matrix(0,NDraws,2)
PostDraws[,2]<-((n-1)*s2)/rchisq(NDraws,n-1)
PostDraws[,1]<- xBar +rnorm(NDraws,0,1)*sqrt(PostDraws[,2]/n)
return(PostDraws)
}
NDraws = 10000
PostDraws<-NormalNonInfoPrior(NDraws, xBar, s2)
PostDraws[1:10,]
hist(PostDraws[,1], 50)
hist(PostDraws[,2], 50)
hist(PostDraws[,1], 50)
sum(PostDraws[,1]<1)
sum(PostDraws[,1]<1)/NDraws
SimDirichlet <- function(nIter, param){
nCat <- length(param)
thetaDraws <- as.data.frame(matrix(NA, nIter, nCat)) # Storage.
for (j in 1:nCat){
thetaDraws[,j] <- rgamma(nIter,param[j],1)
}
for (i in 1:nIter){
thetaDraws[i,] = thetaDraws[i,]/sum(thetaDraws[i,])
}
return(thetaDraws)
}
# Data and prior
set.seed(123) # Set the seed for reproducibility
y <- c(180,230,62,41) # The cell phone survey data (K=4)
alpha <- c(15,15,10,10)*10 # Dirichlet prior hyperparameters
nIter <- 1000 # Number of posterior draws
thetaDraws <- SimDirichlet(nIter,y + alpha)
names(thetaDraws) <- c('theta1','theta2','theta3','theta4')
head(thetaDraws)
par(mfrow = c(1,2)) # Splits the graphical window in four parts
hist(thetaDraws[,1], breaks = 25, xlab = 'Fraction IPhone users', main ='iPhone', freq = FALSE)
lines(density(thetaDraws[,1]), col = "blue", lwd = 2)
hist(thetaDraws[,2], breaks = 25, xlab = 'Fraction Android users', main ='Android', freq = FALSE)
lines(density(thetaDraws[,2]), col = "blue", lwd = 2)
# Computing the posterior probability that Android is the largest
PrAndroidLargest <- sum(thetaDraws[,2]>apply(thetaDraws[,c(1,3,4)],1,max))/nIter
message(paste('Pr(Android has the largest market share) = ', PrAndroidLargest))
###########   BEGIN USER INPUTS   ################
Probit <- 0 # If Probit <-0, then logistic model is used.
chooseCov <- c(1:16) # Here we choose which covariates to include in the model
tau <- 100; # Prior scaling factor such that Prior Covariance = (tau^2)*I
# install.packages("mvtnorm") # Loading a package that contains the multivariate normal pdf
library("mvtnorm") # This command reads the mvtnorm package into R's memory. NOW we can use dmvnorm function.
# Loading data from file
Data<-read.table("SpamReduced.dat",header=TRUE)  # Spam data from Hastie et al.
setwd('~/Dropbox/Teaching/BayesLearningLiU/Code/OptimizeSpamR/')
# Loading data from file
Data<-read.table("SpamReduced.dat",header=TRUE)  # Spam data from Hastie et al.
y <- as.vector(Data[,1]); # Data from the read.table function is a data frame. Let's convert y and X to vector and matrix.
X <- as.matrix(Data[,2:17]);
covNames <- names(Data)[2:length(names(Data))];
X <- X[,chooseCov]; # Here we pick out the chosen covariates.
covNames <- covNames[chooseCov];
nPara <- dim(X)[2];
# Setting up the prior
mu <- as.vector(rep(0,nPara)) # Prior mean vector
Sigma <- tau^2*diag(nPara);
LogPostLogistic <- function(betaVect,y,X,mu,Sigma){
nPara <- length(betaVect);
linPred <- X%*%betaVect;
logLik <- sum( linPred*y -log(1 + exp(linPred)));
if (abs(logLik) == Inf) logLik = -20000; # Likelihood is not finite, stear the optimizer away from here!
logPrior <- dmvnorm(betaVect, matrix(0,nPara,1), Sigma, log=TRUE);
return(logLik + logPrior)
}
# Different starting values. Ideally, any random starting value gives you the same optimum (i.e. optimum is unique)
initVal <- as.vector(rep(0,dim(X)[2]));
# Different starting values. Ideally, any random starting value gives you the same optimum (i.e. optimum is unique)
initVal <- as.vector(solve(crossprod(X,X))%*%t(X)%*%y);
if (Probit==1){
logPost = LogPostProbit;
} else{
logPost = LogPostLogistic;
}
OptimResults<-optim(initVal,logPost,gr=NULL,y,X,mu,Sigma,method=c("BFGS"),control=list(fnscale=-1),hessian=TRUE)
# Printing the results to the screen
names(OptimResults$par) <- covNames # Naming the coefficient by covariates
approxPostStd <- sqrt(diag(-solve(OptimResults$hessian))) # Computing approximate standard deviations.
names(approxPostStd) <- covNames # Naming the coefficient by covariates
print('The posterior mode is:')
print(OptimResults$par)
print('The posterior mode is:')
print(OptimResults$par)
print('The approximate posterior standard deviation is:')
approxPostStd <- sqrt(diag(-solve(OptimResults$hessian)))
print(approxPostStd)
read.csv()
D = read.table('~/Desktop/LidarData.dat')
D[1:5,:]
D[1:5,]
D = read.table('~/Desktop/LidarData.dat', header = TRUE)
D[1:5,]
mean(D)
plot(D[,2],D[,1])
